name: train-dist-7b-a100

resources:
  accelerators: {A100-80GB:8}
  cloud: runpod

# this is the distributed part
num_nodes: 1

file_mounts:
  /output:
    source: s3://jpt-output
    mode: MOUNT

workdir: ~/Developer/jpt

setup: |
  echo "setup"

run: |
  export LD_LIBRARY_PATH=$(echo $LD_LIBRARY_PATH | sed 's|:/usr/local/cuda/lib64||g; s|/usr/local/cuda/lib64:||g; s|/usr/local/cuda/lib64||g')

  requirements_path="requirements/requirements.txt"
  env_name="train"
  source ./bash/setup.sh; activate_or_create_conda_env $env_name $requirements_path
  source ./bash/setup.sh; clean_tmp
  
  pip uninstall mosaicml-streaming -y
  
  sudo chmod go+rw /output
  sudo mkdir /copy
  sudo chmod go+rw /copy
  
  num_nodes=`echo "$SKYPILOT_NODE_IPS" | wc -l`
  master_addr=`echo "$SKYPILOT_NODE_IPS" | head -n1`
  nproc_per_node=${SKYPILOT_NUM_GPUS_PER_NODE}
  node_rank=${SKYPILOT_NODE_RANK}

  echo "num_nodes: $num_nodes"
  echo "master_addr: $master_addr"
  echo "nproc_per_node: $nproc_per_node"
  echo "node_rank: $node_rank"
  
  #PYTHONFAULTHANDLER=1
  
  kill $(lsof -ti :8008 | head -n 1)
  rm -rf /copy/7b_v100_fsdp_03_28_24/checkpoints/*

  source keys.env;  torchrun  \
  --nproc_per_node=$nproc_per_node \
  --node_rank=$node_rank \
  --nnodes=$num_nodes \
  --master_addr=$master_addr \
  --master_port=8008 \
  -m training.train --config ./configs/train/train_7b_fsdp.yaml
