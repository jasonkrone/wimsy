wandb:
  project_name: baseline_eval
  run_name: null

compute:
  device: cuda
  is_distributed: True

seed: &seed 414

eval_vars:
  do_apply_chat_template: &do_apply_chat_template False
  ifeval_max_gen_toks: &ifeval_max_gen_toks 3840

include: configs/eval/test_eval/_test_evals_yaml

baselines:
  ########################################################################################
  #                                        Base Models                                   #
  ########################################################################################


  # llama 3 8B 
  #llama-3dot1-8b:
  #  id: hf
  #  args: pretrained=meta-llama/Llama-3.1-8B
  ## llama 3 8B instruct
  #llama-3dot1-8b-instruct:
  #  id: hf
  #  args: pretrained=meta-llama/Meta-Llama-3.1-8B-Instruct
  # tulu v3 SFT
  #tulu-3-8b-sft:
  #  id: hf
  #  args: pretrained=allenai/Llama-3.1-Tulu-3-8B-SFT
  ## tulu v3 DPO
  #tulu-3-8b-dpo:
  #  id: hf
  #  args: pretrained=allenai/Llama-3.1-Tulu-3-8B-DPO
  #my-llama8b-3dot1-sft-02-24-25:
  #  id: hf
  #  args: pretrained=jasonkrone/02-04-25-llama8b-3dot1-sft-v0dot3-og-lr-1node,tokenizer=allenai/Llama-3.1-Tulu-3-8B-SFT
  #my-llama8b-3dot1-sft-lower-lr:
  #  id: hf
  #  args: pretrained=jasonkrone/02-06-25-llama8b-3dot1-sft-v0dot4-lower-lr-1node,tokenizer=allenai/Llama-3.1-Tulu-3-8B-SFT
  #ai2-code-repro-tulu-3-8b-dpo:
  #  id: hf
  #  args: pretrained=jasonkrone/open_instruct_dev,revision=02_15_25_ai2_source_code_llama3dot1_8b_dpo__allenai_Llama-3.1-Tulu-3-8B-SFT__42__1739743510

  ai2-code-repro-tulu-3-8b-sft:
    id: hf
    args: pretrained=jasonkrone/open_instruct_dev,revision=tulu-3-8b-sft-ai2-02-15-25__123__1739808005


# model info will be set by scripts to the baseline info above
model:
  id: null
  args: null

test_eval:
  clear_cache: True
  include_path: ./tasks
  log_samples: True
  limit: null
  output_path: /output/baselines
  tasks:
    <<: *test_eval_tasks
   